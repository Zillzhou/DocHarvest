"""
åå°å·¥ä½œçº¿ç¨‹
è´Ÿè´£å¼‚æ­¥æ‰§è¡ŒWikiçˆ¬å–ä»»åŠ¡
"""
from PyQt5.QtCore import QThread, pyqtSignal
from feishu_api import FeishuAPI


class WikiWorkerThread(QThread):
    """Wikiçˆ¬å–å·¥ä½œçº¿ç¨‹"""
    
    # å®šä¹‰ä¿¡å·
    log_signal = pyqtSignal(str)
    progress_signal = pyqtSignal(int)
    finished_signal = pyqtSignal(bool, str)
    
    def __init__(self, app_id: str, app_secret: str, wiki_link: str, save_path: str, 
                 export_formats: list = None, use_parallel: bool = True, max_workers: int = 3,
                 turbo_mode: bool = False):
        super().__init__()
        self.app_id = app_id
        self.app_secret = app_secret
        self.wiki_link = wiki_link
        self.save_path = save_path
        self.export_formats = export_formats or ['md']
        self.use_parallel = use_parallel
        self.max_workers = max_workers
        self.turbo_mode = turbo_mode
    
    def run(self):
        """æ‰§è¡ŒWikiæ‰¹é‡çˆ¬å–ä»»åŠ¡"""
        try:
            # åˆå§‹åŒ–APIå®¢æˆ·ç«¯
            self.log_signal.emit("ğŸš€ åˆå§‹åŒ–é£ä¹¦APIå®¢æˆ·ç«¯...")
            api = FeishuAPI(self.app_id, self.app_secret)
            self.progress_signal.emit(10)
            
            # è·å–access_token
            self.log_signal.emit("ğŸ”‘ æ­£åœ¨è·å–access_token...")
            token = api.get_tenant_access_token()
            if not token:
                self.finished_signal.emit(False, "è·å–access_tokenå¤±è´¥ï¼Œè¯·æ£€æŸ¥App IDå’ŒApp Secret")
                return
            self.progress_signal.emit(20)
            
            # åˆå§‹åŒ–Wikiçˆ¬å–å™¨
            if self.turbo_mode:
                # æé€Ÿæ¨¡å¼ - ä½¿ç”¨å¼‚æ­¥çˆ¬å–å™¨
                from async_exporter import AsyncParallelWikiCrawler
                crawler = AsyncParallelWikiCrawler(api, self.export_formats, self.max_workers)
                self.log_signal.emit(f"ğŸš€ æé€Ÿæ¨¡å¼ (å¹¶å‘æ•°: {self.max_workers})")
            elif self.use_parallel:
                from parallel_crawler import ParallelWikiCrawler
                crawler = ParallelWikiCrawler(api, self.export_formats, self.max_workers)
                self.log_signal.emit(f"âš¡ å¹¶è¡Œæ¨¡å¼ (å¹¶è¡Œæ•°: {self.max_workers})")
            else:
                from wiki_crawler import WikiCrawler
                crawler = WikiCrawler(api, self.export_formats)
                self.log_signal.emit("ğŸ“Š ä¸²è¡Œæ¨¡å¼")
            
            self.progress_signal.emit(30)
            
            # å¼€å§‹çˆ¬å–
            count, error = crawler.crawl_wiki(
                self.wiki_link,
                self.save_path
            )
            
            self.progress_signal.emit(100)
            
            if error:
                self.finished_signal.emit(False, f"çˆ¬å–å¤±è´¥: {error}")
            elif count > 0:
                self.finished_signal.emit(True, f"ğŸ‰ çˆ¬å–å®Œæˆï¼å…±å¯¼å‡º {count} ç¯‡æ–‡æ¡£")
            else:
                self.finished_signal.emit(False, "æœªæ‰¾åˆ°ä»»ä½•æ–‡æ¡£")
                
        except Exception as e:
            self.log_signal.emit(f"âŒ é”™è¯¯: {str(e)}")
            self.finished_signal.emit(False, f"å‘ç”Ÿé”™è¯¯: {str(e)}")
